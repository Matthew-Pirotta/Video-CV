{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e0f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features(descriptors1, descriptors2, ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Matches descriptors between two sets.\n",
    "\n",
    "    Args:\n",
    "        descriptors1 (np.array): Descriptors from the first image.\n",
    "        descriptors2 (np.array): Descriptors from the second image.\n",
    "        ratio_thresh (float): Lowe's ratio test threshold.\n",
    "\n",
    "    Returns:\n",
    "        list: Filtered DMatch objects.\n",
    "    \"\"\"\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return []\n",
    "    if descriptors1.dtype != np.float32: # BFMatcher (and FLANN LSH) might expect specific types\n",
    "        descriptors1 = descriptors1.astype(np.float32)\n",
    "    if descriptors2.dtype != np.float32:\n",
    "        descriptors2 = descriptors2.astype(np.float32)\n",
    "\n",
    "    # Determine descriptor type for matcher (ORB are binary, SIFT are float)\n",
    "    is_binary_descriptor = False\n",
    "    if descriptors1.dtype == np.uint8: # Common for ORB, BRIEF\n",
    "        is_binary_descriptor = True\n",
    "\n",
    "    # NORM_HAMMING for binary descriptors (ORB), NORM_L2 for float (SIFT)\n",
    "    norm_type = cv2.NORM_HAMMING if is_binary_descriptor else cv2.NORM_L2\n",
    "    bf = cv2.BFMatcher(norm_type, crossCheck=False) # crossCheck=True is stricter matching\n",
    "\n",
    "    # Perform k-NN matching\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_outliers_ransac(keypoints1, keypoints2, matches, reproj_thresh=3.0, confidence=0.99, max_iters=1000):\n",
    "    \"\"\"\n",
    "    Rejects outlier matches using RANSAC with Fundamental Matrix estimation.\n",
    "\n",
    "    Args:\n",
    "        keypoints1 (list): Keypoints from the first image.\n",
    "        keypoints2 (list): Keypoints from the second image.\n",
    "        matches (list): List of DMatch objects (raw matches).\n",
    "        reproj_thresh (float): Maximum allowed reprojection error to treat a point pair as an inlier.\n",
    "        confidence (float): Desired confidence that the estimated matrix is correct.\n",
    "        max_iters (int): Maximum number of iterations for RANSAC.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list of DMatch objects (inliers), np.array (mask of inliers), np.array (Fundamental Matrix))\n",
    "    \"\"\"\n",
    "    if not matches:\n",
    "        return [], [], None\n",
    "\n",
    "    # Convert keypoints to cv2.Point2f (float) format\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Find Fundamental Matrix and inlier mask using RANSAC\n",
    "    # F is the Fundamental Matrix\n",
    "    # mask is a boolean array where 1 means inlier, 0 means outlier\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, reproj_thresh, confidence, max_iters)\n",
    "\n",
    "    # Filter matches based on the mask\n",
    "    inlier_matches = []\n",
    "    if mask is not None:\n",
    "        for i, m in enumerate(matches):\n",
    "            if mask[i] == 1:\n",
    "                inlier_matches.append(m)\n",
    "\n",
    "    return inlier_matches, mask.ravel(), F # .ravel() converts mask to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matches(img1, keypoints1, img2, keypoints2, matches, inlier_mask=None, title=\"Matches\"):\n",
    "    \"\"\"\n",
    "    Visualizes feature matches between two images.\n",
    "\n",
    "    Args:\n",
    "        img1 (np.array): First image (BGR).\n",
    "        keypoints1 (list): Keypoints from the first image.\n",
    "        img2 (np.array): Second image (BGR).\n",
    "        keypoints2 (list): Keypoints from the second image.\n",
    "        matches (list): List of DMatch objects.\n",
    "        inlier_mask (np.array, optional): Boolean mask for inliers (1) and outliers (0).\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    if inlier_mask is not None:\n",
    "        # Draw inliers (green) and outliers (red)\n",
    "        img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None,\n",
    "                                      matchColor=(0, 255, 0), # Green for inliers\n",
    "                                      singlePointColor=(255, 0, 0), # Red for outliers\n",
    "                                      matchesMask=inlier_mask.tolist(), # Convert mask to list for cv2.drawMatches\n",
    "                                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "    else:\n",
    "        # Draw all matches in default color\n",
    "        img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None,\n",
    "                                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_features_orb_bf(descriptors1, descriptors2, ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Matches ORB descriptors between two sets using Brute-Force Matcher with NORM_HAMMING.\n",
    "    Applies Lowe's ratio test.\n",
    "\n",
    "    Args:\n",
    "        descriptors1 (np.array): ORB Descriptors from the first image.\n",
    "        descriptors2 (np.array): ORB Descriptors from the second image.\n",
    "        ratio_thresh (float): Lowe's ratio test threshold.\n",
    "\n",
    "    Returns:\n",
    "        list: Filtered DMatch objects.\n",
    "    \"\"\"\n",
    "    if descriptors1 is None or descriptors2 is None or len(descriptors1) == 0 or len(descriptors2) == 0:\n",
    "        return []\n",
    "\n",
    "    # ORB descriptors are binary, so NORM_HAMMING is appropriate\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "    # Perform k-NN matching (k=2 for ratio test)\n",
    "    # Ensure descriptors are of type CV_32F or CV_8U, match them to be safe\n",
    "    descriptors1_ = np.float32(descriptors1) if descriptors1.dtype != np.float32 else descriptors1\n",
    "    descriptors2_ = np.float32(descriptors2) if descriptors2.dtype != np.float32 else descriptors2\n",
    "\n",
    "    # Using try-except for knnMatch as it can sometimes fail if not enough descriptors\n",
    "    try:\n",
    "        matches = bf.knnMatch(descriptors1_, descriptors2_, k=2)\n",
    "    except cv2.error as e:\n",
    "        print(f\"Error during knnMatch: {e}. Skipping match for this pair.\")\n",
    "        return []\n",
    "\n",
    "    # Apply Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "def reject_outliers_ransac(keypoints1, keypoints2, matches, reproj_thresh=3.0, confidence=0.99, max_iters=1000):\n",
    "    \"\"\"\n",
    "    Rejects outlier matches using RANSAC with Fundamental Matrix estimation.\n",
    "\n",
    "    Args:\n",
    "        keypoints1 (list): Keypoints from the first image.\n",
    "        keypoints2 (list): Keypoints from the second image.\n",
    "        matches (list): List of DMatch objects (raw matches).\n",
    "        reproj_thresh (float): Maximum allowed reprojection error to treat a point pair as an inlier.\n",
    "        confidence (float): Desired confidence that the estimated matrix is correct.\n",
    "        max_iters (int): Maximum number of iterations for RANSAC.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list of DMatch objects (inliers), np.array (mask of inliers), np.array (Fundamental Matrix))\n",
    "    \"\"\"\n",
    "    if not matches or len(matches) < 8: # Need at least 8 points for Fundamental Matrix\n",
    "        print(\"Not enough matches to perform RANSAC (need at least 8).\")\n",
    "        return [], [], None\n",
    "\n",
    "    # Convert keypoints to cv2.Point2f (float) format\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Find Fundamental Matrix and inlier mask using RANSAC\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, reproj_thresh, confidence, max_iters)\n",
    "\n",
    "    # Filter matches based on the mask\n",
    "    inlier_matches = []\n",
    "    if mask is not None:\n",
    "        for i, m in enumerate(matches):\n",
    "            if mask[i] == 1:\n",
    "                inlier_matches.append(m)\n",
    "\n",
    "    return inlier_matches, mask.ravel(), F # .ravel() converts mask to 1D array\n",
    "\n",
    "\n",
    "def visualize_matches(img1, keypoints1, img2, keypoints2, matches, inlier_mask=None, title=\"Matches\"):\n",
    "    \"\"\"\n",
    "    Visualizes feature matches between two images.\n",
    "\n",
    "    Args:\n",
    "        img1 (np.array): First image (BGR).\n",
    "        keypoints1 (list): Keypoints from the first image.\n",
    "        img2 (np.array): Second image (BGR).\n",
    "        keypoints2 (list): Keypoints from the second image.\n",
    "        matches (list): List of DMatch objects.\n",
    "        inlier_mask (np.array, optional): Boolean mask for inliers (1) and outliers (0).\n",
    "        title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    if inlier_mask is not None:\n",
    "        # Draw inliers (green) and outliers (red)\n",
    "        img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None,\n",
    "                                      matchColor=(0, 255, 0), # Green for inliers\n",
    "                                      singlePointColor=(255, 0, 0), # Red for outliers\n",
    "                                      matchesMask=inlier_mask.tolist(), # Convert mask to list for cv2.drawMatches\n",
    "                                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "    else:\n",
    "        # Draw all matches in default color\n",
    "        img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None,\n",
    "                                      flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    plt.figure(figsize=(18, 9))\n",
    "    plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Execution for Part 4\n",
    "\n",
    "# %%\n",
    "print(\"\\n--- Running Feature Matching and Outlier Rejection (ORB & Brute-Force) ---\")\n",
    "\n",
    "# Iterate through the chosen display_pair_indices_for_matching\n",
    "for i in display_pair_indices_for_matching:\n",
    "    j = i + 1\n",
    "\n",
    "    if j >= len(frames):\n",
    "        continue # Should not happen with correct display_pair_indices_for_matching setup\n",
    "\n",
    "    img1 = frames[i]\n",
    "    img2 = frames[j]\n",
    "\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    print(f\"\\nProcessing Frame Pair: {i} and {j}\")\n",
    "\n",
    "    # 1. Feature Detection & Description (using ORB)\n",
    "    keypoints1, descriptors1 = detect_orb(gray1)\n",
    "    keypoints2, descriptors2 = detect_orb(gray2)\n",
    "\n",
    "    print(f\"  - Frame {i}: {len(keypoints1)} ORB keypoints\")\n",
    "    print(f\"  - Frame {j}: {len(keypoints2)} ORB keypoints\")\n",
    "\n",
    "    # 2. Feature Matching (Brute-Force)\n",
    "    raw_matches = match_features_orb_bf(descriptors1, descriptors2, ratio_thresh=0.75)\n",
    "    print(f\"  - Initial matches (after ratio test): {len(raw_matches)}\")\n",
    "\n",
    "    # Visualize raw matches (before RANSAC)\n",
    "    if raw_matches:\n",
    "        visualize_matches(img1, keypoints1, img2, keypoints2, raw_matches,\n",
    "                          title=f\"Raw ORB-BF Matches (Frame {i} to {j}) - {len(raw_matches)} matches\")\n",
    "    else:\n",
    "        print(f\"  - No initial matches found for Frame {i} to {j}.\")\n",
    "        continue # Skip RANSAC if no matches\n",
    "\n",
    "    # 3. Outlier Rejection with RANSAC (using Fundamental Matrix)\n",
    "    inlier_matches, inlier_mask, F_matrix = reject_outliers_ransac(keypoints1, keypoints2, raw_matches,\n",
    "                                                                   reproj_thresh=3.0) # Adjust threshold as needed\n",
    "\n",
    "    print(f\"  - Inlier matches after RANSAC: {len(inlier_matches)}\")\n",
    "    if F_matrix is not None:\n",
    "        print(f\"  - Fundamental Matrix (F) calculated:\\n{np.array2string(F_matrix, precision=4, suppress_small=True)}\")\n",
    "    else:\n",
    "        print(\"  - Could not compute Fundamental Matrix (not enough inliers or degenerate case).\")\n",
    "\n",
    "    # 4. Visualize matches after RANSAC\n",
    "    if inlier_matches:\n",
    "        visualize_matches(img1, keypoints1, img2, keypoints2, raw_matches, inlier_mask=inlier_mask,\n",
    "                          title=f\"ORB-BF Matches After RANSAC (Frame {i} to {j}) - {len(inlier_matches)} inliers\")\n",
    "    else:\n",
    "        print(f\"  - No inlier matches after RANSAC for Frame {i} to {j}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
