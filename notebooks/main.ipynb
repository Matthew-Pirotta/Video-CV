{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb680e4d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27bcbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio.v3 as iio\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3903994",
   "metadata": {},
   "source": [
    "# 1. Video Acquisition  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61a469",
   "metadata": {},
   "source": [
    "# 2. Frame Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "850110fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_indices(video_path:str, num_frames:int) -> list:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "\n",
    "    if num_frames > total_frames:\n",
    "        raise ValueError(f\"Requested {num_frames} frames, but video has only {total_frames} frames.\")\n",
    "\n",
    "    # Compute evenly spaced indices\n",
    "    indices = np.linspace(0, total_frames - 1, num=num_frames, dtype=int)\n",
    "    return indices.tolist()\n",
    "\n",
    "def load_specific_frames(video_path:str, selected_indices:list, display_frames=True) -> list:\n",
    "    frames = []\n",
    "    selected_set = set(selected_indices)\n",
    "    frame_count = 0\n",
    "\n",
    "    try:\n",
    "        for frame in iio.imiter(video_path):\n",
    "            if frame_count in selected_set:\n",
    "                frames.append(frame)\n",
    "\n",
    "                if display_frames:\n",
    "                    plt.imshow(frame)\n",
    "                    plt.title(f'Frame {frame_count}')\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the video: {e}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\nFinished loading selected frames.\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889bac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished loading selected frames.\n",
      "Total frames processed: 291\n"
     ]
    }
   ],
   "source": [
    "video_path = \"../videos/vid1.mp4\"\n",
    "indices = get_frame_indices(video_path, num_frames=15)\n",
    "frames = load_specific_frames(video_path, selected_indices=indices, display_frames=False)\n",
    "pair_indices = list(range(len(frames) - 1))  # Pairs: (0,1), (1,2), ..., (n-2, n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d647f",
   "metadata": {},
   "source": [
    "# 3. Feature Detection and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9955719a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd36032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_orb(gray):\n",
    "    orb = cv2.ORB_create(nfeatures=3000)\n",
    "    return orb.detect(gray, None)\n",
    "\n",
    "def detect_sift(gray):\n",
    "    sift = cv2.SIFT_create(nfeatures=3000, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6)\n",
    "    keypoints, _ = sift.detectAndCompute(gray, None)\n",
    "    return keypoints\n",
    "\n",
    "def detect_fast(gray):\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=25, nonmaxSuppression=True)\n",
    "    return fast.detect(gray, None)\n",
    "\n",
    "def detect_shi_tomasi(gray):\n",
    "    corners = cv2.goodFeaturesToTrack(gray, maxCorners=3000, qualityLevel=0.01, minDistance=10, blockSize=3)\n",
    "    if corners is not None:\n",
    "        return [cv2.KeyPoint(float(x), float(y), 1) for [[x, y]] in corners]\n",
    "    return []\n",
    "\n",
    "def detect_harris(gray, block_size=2, ksize=3, k=0.04, threshold_ratio=0.01):\n",
    "    gray_f32 = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray_f32, block_size, ksize, k)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    threshold = threshold_ratio * dst.max()\n",
    "    corners = np.argwhere(dst > threshold)\n",
    "    return [cv2.KeyPoint(float(pt[1]), float(pt[0]), 1) for pt in corners]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70779144",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24720f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_detector_pairs(frames, pair_indices, detector_fn, title_prefix=\"Detector\"):\n",
    "    #pair_indices = list(pair_indices)  # Ensure it's a list, not a numpy array\n",
    "\n",
    "    if len(frames) < 2:\n",
    "        print(\"Error: At least two frames are necessary.\")\n",
    "        return\n",
    "\n",
    "    max_index = len(frames) - 2\n",
    "    invalid_indices = [i for i in pair_indices if i < 0 or i > max_index]\n",
    "    if invalid_indices:\n",
    "        print(f\"Error: Invalid indices found: {invalid_indices}. Must be in range 0 to {max_index}.\")\n",
    "        return\n",
    "\n",
    "    for idx, i in enumerate(pair_indices, 1):\n",
    "        j = i + 1\n",
    "        img1 = cv2.cvtColor(frames[i], cv2.COLOR_BGR2GRAY)\n",
    "        img2 = cv2.cvtColor(frames[j], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        keypoints1 = detector_fn(img1)\n",
    "        keypoints2 = detector_fn(img2)\n",
    "\n",
    "        print(f\"\\nPair {idx}: Frame {i} and Frame {j}\")\n",
    "        print(f\"- Keypoints in Frame {i}: {len(keypoints1)}\")\n",
    "        print(f\"- Keypoints in Frame {j}: {len(keypoints2)}\")\n",
    "\n",
    "        img_kp1 = cv2.drawKeypoints(img1, keypoints1, None, color=(0, 255, 0))\n",
    "        img_kp2 = cv2.drawKeypoints(img2, keypoints2, None, color=(0, 255, 0))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        axes[0].imshow(img_kp1, cmap='gray')\n",
    "        axes[0].set_title(f\"{title_prefix} - Frame {i}\")\n",
    "        axes[1].imshow(img_kp2, cmap='gray')\n",
    "        axes[1].set_title(f\"{title_prefix} - Frame {j}\")\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.suptitle(f\"{title_prefix} Comparison: Pair {idx}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be8dfc",
   "metadata": {},
   "source": [
    "### ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid indices found: [20, 41, 61, 82, 102, 123, 144, 164, 185, 205, 226, 246, 267, 288]. Must be in range 0 to 13.\n"
     ]
    }
   ],
   "source": [
    "run_feature_detector_pairs(frames, pair_indices, detect_orb, title_prefix=\"ORB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5145c",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid indices found: [20, 41, 61, 82, 102, 123, 144, 164, 185, 205, 226, 246, 267, 288]. Must be in range 0 to 13.\n"
     ]
    }
   ],
   "source": [
    "run_feature_detector_pairs(frames, pair_indices, detect_sift, title_prefix=\"SIFT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fff53e",
   "metadata": {},
   "source": [
    "### FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid indices found: [20, 41, 61, 82, 102, 123, 144, 164, 185, 205, 226, 246, 267, 288]. Must be in range 0 to 13.\n"
     ]
    }
   ],
   "source": [
    "run_feature_detector_pairs(frames, pair_indices, detect_fast, title_prefix=\"FAST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9a8a0",
   "metadata": {},
   "source": [
    "### SHI-TOMASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b42c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid indices found: [20, 41, 61, 82, 102, 123, 144, 164, 185, 205, 226, 246, 267, 288]. Must be in range 0 to 13.\n"
     ]
    }
   ],
   "source": [
    "run_feature_detector_pairs(frames, pair_indices, detect_shi_tomasi, title_prefix=\"Shi-Tomasi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380793a",
   "metadata": {},
   "source": [
    "### Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffcf2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid indices found: [20, 41, 61, 82, 102, 123, 144, 164, 185, 205, 226, 246, 267, 288]. Must be in range 0 to 13.\n"
     ]
    }
   ],
   "source": [
    "run_feature_detector_pairs(frames, pair_indices, detect_harris, title_prefix=\"Harris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63df05",
   "metadata": {},
   "source": [
    "# 4. Feature Matching and Outlier Rejection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213ae0e",
   "metadata": {},
   "source": [
    "# 5. Essential/Fundamental Matrix Computation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1123511",
   "metadata": {},
   "source": [
    "# 6. Camera Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a4d20",
   "metadata": {},
   "source": [
    "# 7. 3D Point Triangulation and Scene Visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b949f",
   "metadata": {},
   "source": [
    "# 8.Evaluation and Analysis "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
